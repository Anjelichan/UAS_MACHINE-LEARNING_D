{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Le0tIj7YzsF0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ukuran grid 5x5\n",
        "grid_size = 5\n",
        "#state tujuan (goal state)\n",
        "goal_state = (4, 4)\n",
        "#state awal\n",
        "start_state = (0, 0)\n",
        "\n",
        "# Q-table dengan dimensi (grid_size, grid_size, 4)\n",
        "# diinisialisasi ke nol, dimana 4 adalah jumlah aksi (atas, bawah,kiri,kanan)\n",
        "Q = np.zeros((grid_size, grid_size, 4))\n",
        "#daftar aksi: 0=atas, 1=bawah, 2=kiri, 3=kanan\n",
        "actions = [0, 1, 2, 3]\n",
        "\n",
        "#fungsi untuk memilih aksi menggunakan epsilon-greedy\n",
        "def take_action(state, epsilon=0.1):\n",
        "  #dengan probilitas epsilon, pilih aksi secara acak (eksplorasi)\n",
        "    if random.uniform(0, 1) < epsilon:\n",
        "        return random.choice(actions)\n",
        "    else:\n",
        "      #dengan probilitas (1 - epsilon), pilih aksi terbaik berdasarkan Q-table (eksploitasi)\n",
        "        return np.argmax(Q[state[0], state[1]])\n",
        "\n",
        "#fungsi untuk menentukan state berikutnya berdasarkan aksi\n",
        "def get_next_state(state, action):\n",
        "    if action == 0: #aksi 'atas'\n",
        "        next_state = (max(state[0] - 1, 0), state[1])\n",
        "    elif action == 1: #aksi 'bawah'\n",
        "        next_state = (min(state[0] + 1, grid_size -1), state[1])\n",
        "    elif action == 2: #aksi 'kiri'\n",
        "        next_state = (state[0], max(state[1] - 1, 0))\n",
        "    elif action == 3: #aksi 'kanan'\n",
        "        next_state = (state[0], min(state[1] + 1, grid_size -1))\n",
        "    return next_state\n",
        "\n",
        "#fungsi untuk menentukan reward\n",
        "def get_reward(state, next_state):\n",
        "    if next_state == goal_state:\n",
        "        return 1 #reward positif jika mencapai goal state\n",
        "    else:\n",
        "        return -0.01 #penalti kecil untuk setiap langkah (agar jalur optimal ditemukan )\n",
        "\n",
        "#parameter pembelajaran\n",
        "alpha = 0.1 #learning rate\n",
        "gamma = 0.9 #discount factor\n",
        "epsilon = 0.1 #probalitas eksplorasi awal\n",
        "episodes = 1000 #jumlah episode\n",
        "\n",
        "#pelatihan menggunakan Q-learning\n",
        "for episode in range(episodes):\n",
        "    state =start_state #mulai dari state awal\n",
        "    while state != goal_state: #loop hingga mencapai goal state\n",
        "    #pilih aksi menggunkan epsilon-greedy\n",
        "        action = take_action(state, epsilon)\n",
        "        #dapatkan state berikutnya berdasarkan aksi\n",
        "        next_state = get_next_state(state, action)\n",
        "        #hitung reward\n",
        "        reward = get_reward(state, next_state)\n",
        "\n",
        "        #update nilai Q untuk state dan aksi saat ini\n",
        "        Q[state[0], state[1], action] = Q[state[0], state[1], action] + alpha * (reward + gamma * np.max(Q[next_state[0], next_state[1]]) - Q[state[0], state[1], action])\n",
        "\n",
        "        #pindah ke state berikutnya\n",
        "        state = next_state\n",
        "  #kurangi epsilon untuk mengurangi eksplorasi secara bertahap\n",
        "    epsilon = max(0.01, epsilon * 0.995)\n",
        "\n",
        "#cetak Q-table setelah pelatihan\n",
        "print(\"Q-table setelah pelatihan: \")\n",
        "print(Q)\n",
        "\n",
        "#fungsi untuk mendapatkan aksi terbaik dari Q-table\n",
        "def get_best_action(state):\n",
        "    return np.argmax(Q[state[0], state[1]])\n",
        "\n",
        "#menentukan jalur terbaik setelah pelatihan\n",
        "state = start_state #mulai dari state awal\n",
        "path = [state] #simpan jalur yang dilalui\n",
        "while state != goal_state:\n",
        "    action = get_best_action(state) #ambil aksi terbaik dari Q-table\n",
        "    state = get_next_state(state, action) #pindah ke state berikutnya\n",
        "    path.append(state) #tambahkan ke jalur\n",
        "\n",
        "#cetak jalur terbaik yang ditemukan\n",
        "print(\"\\njalan terbaik yang ditemukan oleh agen:\")\n",
        "print(path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e7Pysmb9PA-",
        "outputId": "768ba3cc-73bd-4012-b05a-f87f9e49a8c9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q-table setelah pelatihan: \n",
            "[[[ 0.23603421  0.04682182  0.08905241  0.42612659]\n",
            "  [ 0.04925188  0.4845851   0.2269085   0.07325879]\n",
            "  [-0.01040654  0.38463159  0.07179876 -0.00995703]\n",
            "  [-0.00772553 -0.00595398 -0.00752185 -0.00745009]\n",
            "  [-0.00670788 -0.00644648 -0.00711455 -0.00679347]]\n",
            "\n",
            " [[-0.01588487 -0.01455843 -0.01485358  0.26772718]\n",
            "  [ 0.16785813  0.00408694  0.00831316  0.549539  ]\n",
            "  [ 0.12190713  0.62171     0.1029345   0.03610554]\n",
            "  [-0.00618918  0.23624471 -0.0050836  -0.00585161]\n",
            "  [-0.00591674 -0.00520805 -0.00500721 -0.00490034]]\n",
            "\n",
            " [[-0.01191717 -0.0093438  -0.00950103 -0.00794629]\n",
            "  [-0.0073715  -0.00480841 -0.0070131   0.34428726]\n",
            "  [ 0.25272462  0.7019      0.08775855  0.21240442]\n",
            "  [-0.00360177  0.68834567 -0.00224029 -0.00199   ]\n",
            "  [-0.00394688  0.14214234 -0.0021601  -0.00199   ]]\n",
            "\n",
            " [[-0.00607801 -0.0063351  -0.00679347 -0.00550957]\n",
            "  [-0.00509675 -0.00532987 -0.005131    0.28364293]\n",
            "  [ 0.32905015  0.12243727  0.06327311  0.791     ]\n",
            "  [ 0.1682718   0.33738271  0.31864726  0.89      ]\n",
            "  [ 0.00341423  1.          0.48146128  0.46420925]]\n",
            "\n",
            " [[-0.00490027 -0.0039404  -0.0039404  -0.00479843]\n",
            "  [-0.00497396 -0.0029701  -0.00305029  0.00151487]\n",
            "  [-0.00199    -0.00199    -0.0020791   0.42632283]\n",
            "  [-0.001      -0.001      -0.001       0.89058101]\n",
            "  [ 0.          0.          0.          0.        ]]]\n",
            "\n",
            "jalan terbaik yang ditemukan oleh agen:\n",
            "[(0, 0), (0, 1), (1, 1), (1, 2), (2, 2), (3, 2), (3, 3), (3, 4), (4, 4)]\n"
          ]
        }
      ]
    }
  ]
}
